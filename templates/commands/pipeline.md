---
description: 自动化规格流水线：读取外部需求文档，在隔离 worktree 中自主执行 specify → clarify → plan → tasks → implement
argument-hint: 路径: /path/to/docs 描述: 功能描述
scripts:
  flyway:
    sh: scripts/bash/scan-flyway-versions.sh
    ps: scripts/powershell/scan-flyway-versions.ps1
  alembic:
    sh: scripts/bash/scan-alembic-revisions.sh
    ps: scripts/powershell/scan-alembic-revisions.ps1
  clarify_guard:
    sh: scripts/bash/clarify-requirement-guard.sh
    ps: scripts/powershell/clarify-requirement-guard.ps1
---

## User Input

```text
$ARGUMENTS
```

## Execution

Parse user input and extract:
- **Doc path**: the path after "路径:"
- **Feature description**: the text after "描述:"

If either is missing, ask the user to provide: `路径: /path/to/docs 描述: feature overview`

Get the main repo root (`git rev-parse --show-toplevel`).

### Load Project Config

Read `.specify/.project` to load project-specific settings (generated by `/speckit.init`):

```bash
source .specify/.project
```

This provides: `STACK`, `BUILD_COMMAND`, `TEST_COMMAND`, `TEST_DIR`, `DEPLOY_COMMAND`,
`APP_PORT`, `DOC_PATH`, `MIGRATION_TOOL`, `MIGRATION_PATH`, `SERVICE_LOG_COMMAND`,
`BASE_BRANCH`, `MAX_PARALLEL_WORKERS`, etc.

If `.specify/.project` does not exist, warn the user:
```
WARNING: .specify/.project not found. Run /speckit.init first to detect project config.
```
Then fall back to asking the user for BUILD_COMMAND and TEST_COMMAND before proceeding.

Resolve runtime defaults after loading config:
- `BASE_BRANCH`: use `.specify/.project` value if present; otherwise detect `origin/HEAD`; fallback to `main`.
- `MAX_PARALLEL_WORKERS`: use `.specify/.project` value if present; fallback to `4`; cap at `8`.

### Strict Pipeline Mode (Default)

To reduce workflow drift on lower-capability models, run in strict mode by default:
- Do not advance stage unless gate script exits `0`
- Persist normalized artifact files for each stage (see table below)
- Persist stage receipts for audit/recovery

Initialize runtime context once at the beginning:

**Bash:**
```bash
PIPELINE_ID="$(date +%Y%m%d-%H%M%S)"
RUNTIME_DIR="<main-repo-root>/.specify/pipeline-runtime/${PIPELINE_ID}"
mkdir -p "${RUNTIME_DIR}"
```

**PowerShell:**
```powershell
$PIPELINE_ID = Get-Date -Format 'yyyyMMdd-HHmmss'
$RUNTIME_DIR = "<main-repo-root>/.specify/pipeline-runtime/$PIPELINE_ID"
New-Item -ItemType Directory -Path $RUNTIME_DIR -Force | Out-Null
```

If gate script is missing, stop and tell user to run `/speckit.update` first.

### Normalized Stage Artifacts (Required)

| Stage | Required artifact(s) |
|-------|----------------------|
| 0 | `<RUNTIME_DIR>/docs-summary.md` |
| 1 | `<FEATURE_DIR>/spec.md` |
| 2 | `<FEATURE_DIR>/spec.md` (clarifications with `Source:` anchors) |
| 3 | `<FEATURE_DIR>/plan.md`, `<FEATURE_DIR>/research.md` |
| 3.5 | `<FEATURE_DIR>/impact-pre-analysis.md` |
| 4 | `<FEATURE_DIR>/tasks.md` OR `<FEATURE_DIR>/tasks-index.md` + `tasks-<module>.md` |
| 5 | `<FEATURE_DIR>/implementation-summary.md` |
| 5.5 | `<FEATURE_DIR>/impact-analysis.md` |
| 6 | `<FEATURE_DIR>/code-review.md` |
| 7 | `<FEATURE_DIR>/test-summary.md` |
| 8 | `<FEATURE_DIR>/merge-summary.md` |
| 9 | `<FEATURE_DIR>/deploy-healthcheck.md` OR `<FEATURE_DIR>/deploy-skipped.md` |

### Mandatory Stage Gate

For **every** stage `N`, execute these steps in order:
1. Write/update the stage artifact file(s) from the table above.
2. Write `<RUNTIME_DIR>/stage-N.receipt.json`:
   ```json
   {
     "stage": "N",
     "status": "completed",
     "next_stage": "N+1",
     "retries": 0,
     "evidence": ["<artifact-path-1>", "<artifact-path-2>"]
   }
   ```
3. Run gate script (must pass):
   - Bash:
     ```bash
     ./.specify/scripts/bash/pipeline-stage-gate.sh --stage N --feature-dir "<FEATURE_DIR>" --worktree-root "<WORKTREE_ROOT>" --docs-summary-file "<RUNTIME_DIR>/docs-summary.md" --main-repo-root "<main-repo-root>" --base-branch "${BASE_BRANCH}" --receipt "<RUNTIME_DIR>/stage-N.receipt.json"
     ```
   - PowerShell:
     ```powershell
     ./.specify/scripts/powershell/pipeline-stage-gate.ps1 -Stage N -FeatureDir "<FEATURE_DIR>" -WorktreeRoot "<WORKTREE_ROOT>" -DocsSummaryFile "<RUNTIME_DIR>/docs-summary.md" -MainRepoRoot "<main-repo-root>" -BaseBranch "${BASE_BRANCH}" -Receipt "<RUNTIME_DIR>/stage-N.receipt.json"
     ```
4. If gate fails: stop immediately and report missing evidence (do not continue to next stage).

Dispatch subagents sequentially (stages 0-4); stage 5 is dispatched directly by this
command via the `coding-worker` agent (tier selected by task file count: low ≤1, medium 2-5, high 6+).
**If any stage times out or fails, retry with the same parameters.**

### Task Granularity Rules

To prevent subagent timeouts caused by overly long context:
- **Split large tasks**: If a task involves multiple files or multi-step operations, split
  it so each subagent handles only 1-2 files.
- **Single dispatch limit**: Each coding worker call MUST handle only one clear
  small task (e.g., "create one Entity class" or "write one Service method"). Never bundle
  an entire Phase into a single subagent.
- **Context trimming**: Only pass the reference information required for the current task
  in the prompt. Do not pass all design documents in full.

### Global Execution Contract

Apply this contract to **every** subagent dispatch (stages 0-9):
- **Chunked write**: Large files (>200 lines) MUST be written in chunks (<=200 lines each). Use Create for first chunk, then Edit to append.
- **Dynamic timeout** (instead of fixed 300s):
  - Small task (<=1 file, low complexity): `timeout=180`
  - Medium task (2-5 files or moderate complexity): `timeout=420`
  - Large task (6+ files, migration-heavy, or integration): `timeout=600`
- **Retry with exponential backoff**:
  - Retry 1: wait 15s
  - Retry 2: wait 30s
  - If still failing after retry 2: split task scope and re-dispatch once
  - If split run still fails: halt and report blocking point
- **Prompt footer**: Dispatcher MUST append a single-line footer to each subagent prompt:
  `Execution Contract: chunked write, dynamic timeout tier, and retry metadata apply.`

Do not duplicate long timeout/chunked-write paragraphs in every stage prompt; use this global contract.

### Parallel Scheduler and Limits

All [P] execution must go through a centralized scheduler:
- **Global concurrency cap**: never dispatch more than `MAX_PARALLEL_WORKERS` tasks concurrently.
- **File mutex**: two tasks touching the same normalized file path MUST NOT run in parallel.
- **Dependency-aware dispatch**: run only tasks whose dependencies are completed.
- **Unknown file scope**: if a task has no explicit file list, run it sequentially.
- **Fair scheduling**: prioritize unblockers first (tasks with highest downstream dependency count), then FIFO.

### Migration Version Conflict Detection

Before stage 5 begins and before each migration task dispatch, run version detection to avoid conflicts across worktrees and branches.

**For Flyway (Java/Spring)**:

Use the provided script to scan all worktrees and branches for occupied Flyway version numbers:

**Bash:**
```bash
./scripts/bash/scan-flyway-versions.sh <main-repo> <WORKTREE_ROOT>
```

**PowerShell:**
```powershell
./scripts/powershell/scan-flyway-versions.ps1 -MainRepo <main-repo> -WorktreeRoot <WORKTREE_ROOT>
```

**For Alembic (Python)**:

Use the provided script to scan for Alembic revision IDs:

**Bash:**
```bash
./scripts/bash/scan-alembic-revisions.sh <main-repo> <WORKTREE_ROOT>
```

**PowerShell:**
```powershell
./scripts/powershell/scan-alembic-revisions.ps1 -MainRepo <main-repo> -WorktreeRoot <WORKTREE_ROOT>
```

**For Prisma (Node.js/TypeScript)**:

Scan migration directories (cross-platform):

**Bash:**
```bash
ls <main-repo>/prisma/migrations/*/migration.sql 2>/dev/null || true
ls <WORKTREE_ROOT>/prisma/migrations/*/migration.sql 2>/dev/null || true
```

**PowerShell:**
```powershell
Get-ChildItem <main-repo>/prisma/migrations/*/migration.sql -ErrorAction SilentlyContinue
Get-ChildItem <WORKTREE_ROOT>/prisma/migrations/*/migration.sql -ErrorAction SilentlyContinue
```

**General procedure**:
- Merge all occupied version numbers/IDs, take the max +1 (or generate next unique ID) as the starting version
- Pass `NEXT_MIGRATION_VERSION` into every subagent prompt that involves database migrations
- If a feature needs multiple migration files, increment sequentially (e.g., V15, V16, V17... for Flyway)
- Update `NEXT_MIGRATION_VERSION` after each migration task completes

---

### Checkpoint Recovery: Stateful and Verifiable

Persist pipeline runtime state to:
`<main-repo-root>/.specify/pipeline-state.json`

Use this schema (minimum fields):
```json
{
  "pipeline_id": "<timestamp-or-uuid>",
  "input_hash": "<sha256(doc_path + feature_description + base_branch + repo_head)>",
  "main_repo_root": "<path>",
  "worktree_root": "<path>",
  "branch_name": "<branch>",
  "feature_dir": "<path>",
  "current_stage": "0|1|2|3|3.5|4|5|5.5|6|7|8|9",
  "stages": {
    "0": {"status": "pending|running|completed|failed", "retry_count": 0, "artifact_hash": "<hash-or-empty>", "updated_at": "<iso8601>"},
    "1": {"status": "..."},
    "2": {"status": "..."}
  }
}
```

Startup recovery procedure:
1. If state file exists, compare `input_hash` with current run input hash.
2. If hash mismatch: archive old state file to `.specify/pipeline-state.<timestamp>.bak.json`, then start from Stage 0.
3. If hash matches: validate artifacts for each completed stage (table below).
4. Resume from the first stage that is not `completed` or fails validation.
5. Report to user:
   `Recovered pipeline state from stage file, validated stages 0-N, resuming at stage N+1.`

Stage artifact validation (minimum checks):

| Stage | Required evidence |
|-------|-------------------|
| 0 | `<RUNTIME_DIR>/docs-summary.md` exists and hash matches `artifact_hash` |
| 1 | `WORKTREE_ROOT`, `BRANCH_NAME`, `FEATURE_DIR` present; `<FEATURE_DIR>/spec.md` exists |
| 2 | `spec.md` contains `## Clarifications` with `Source:` anchors and clarify guard passed |
| 3 | `<FEATURE_DIR>/plan.md` and `<FEATURE_DIR>/research.md` exist |
| 3.5 | `<FEATURE_DIR>/impact-pre-analysis.md` exists |
| 4 | `tasks.md` or (`tasks-index.md` + shard files) exists |
| 5 | `<FEATURE_DIR>/implementation-summary.md` exists and task files show `[x]` markers |
| 5.5 | `<FEATURE_DIR>/impact-analysis.md` exists |
| 6 | `<FEATURE_DIR>/code-review.md` exists and unresolved CRITICAL/HIGH count recorded |
| 7 | `<FEATURE_DIR>/test-summary.md` exists and `${TEST_COMMAND}` pass recorded |
| 8 | `<FEATURE_DIR>/merge-summary.md` exists and merge to `${BASE_BRANCH}` recorded |
| 9 | `<FEATURE_DIR>/deploy-healthcheck.md` or `<FEATURE_DIR>/deploy-skipped.md` exists |

State update rules:
- Before each stage starts: set stage status to `running`, increment `retry_count` if retry.
- After each stage succeeds: set status to `completed`, write stage artifact hash/evidence.
- On failure: set status to `failed`, persist error summary.
- Write state updates atomically (write temp file, then move/rename).

If user input contains only "描述:" without "路径:" and matches an existing worktree/feature,
enter recovery mode and use state file first, artifact scan second.

---

### Stage 0: Read Requirements Documents

All stage prompts below inherit the **Global Execution Contract**; only stage-specific instructions are listed.

```
Task:
  subagent_type: spec-read-docs
  description: "Read requirements docs"
  prompt: |
    Doc path: <parsed path>
    Read all requirements documents under this path and output a structured
    requirements summary.
```

**Checkpoint**:
- Persist summary to `<RUNTIME_DIR>/docs-summary.md` and set `DOCS_SUMMARY` from this file.
- Run Stage 0 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 1: Specify + Worktree

```
Task:
  subagent_type: spec-specify-wt
  description: "Specify + Worktree"
  prompt: |
    Requirements summary:
    <DOCS_SUMMARY>

    Feature description: <parsed description>
    Main repo root: <repo root>

    Create an isolated worktree workspace, populate spec.md and quality checklist.
    MUST return WORKTREE_ROOT, BRANCH_NAME, FEATURE_DIR, and main repo root.

    Multi-Module Decomposition (Constitution v2.3.0):
    Count the number of distinct functional modules in the requirements first.
    - 1 module: spec.md contains all content directly.
    - 2-8 modules: spec.md serves as summary entry point only; create
      spec-<module>.md for each submodule under FEATURE_DIR/specs/.
      Reference: specs/009-asset-lifecycle/.
    - >8 modules: STOP and advise the user to split into multiple branches.
```

**Checkpoint**:
- Confirm WORKTREE_ROOT / BRANCH_NAME / FEATURE_DIR were returned.
- Run Stage 1 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 2: Clarify

Before dispatching clarify agent, snapshot baseline spec:

**Bash:**
```bash
cp "<FEATURE_DIR>/spec.md" "<RUNTIME_DIR>/spec.before-clarify.md"
```

**PowerShell:**
```powershell
Copy-Item -Path "<FEATURE_DIR>/spec.md" -Destination "<RUNTIME_DIR>/spec.before-clarify.md" -Force
```

```
Task:
  subagent_type: spec-clarify-auto
  description: "Auto Clarify"
  prompt: |
    WORKTREE_ROOT: <from stage 1>
    BRANCH_NAME: <from stage 1>
    FEATURE_DIR: <from stage 1>
    Main repo root: <repo root>

    Automatically clarify ambiguities in spec.md, select recommended answers
    and write them back with requirements-lock mode:
    - Default append-only update in `## Clarifications`
    - For each clarification line, include source anchor:
      `- Q: ... -> A: ... | Source: ...`
    - Do NOT modify non-clarification sections unless explicit user-approved
      `CHANGE_REQUEST` is recorded
```

**Checkpoint**:
- Confirm clarify completed and `spec.md` was updated.
- Run clarify guard (must pass) before Stage 2 gate:
  - Bash:
    `./.specify/scripts/bash/clarify-requirement-guard.sh --before "<RUNTIME_DIR>/spec.before-clarify.md" --after "<FEATURE_DIR>/spec.md" --min-clarifications 1`
  - PowerShell:
    `./.specify/scripts/powershell/clarify-requirement-guard.ps1 -Before "<RUNTIME_DIR>/spec.before-clarify.md" -After "<FEATURE_DIR>/spec.md" -MinClarifications 1`
- If clarify guard fails: stop pipeline and ask user to either keep strict append-only clarify mode
  or explicitly approve a `CHANGE_REQUEST`.
- Run Stage 2 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 3: Plan

```
Task:
  subagent_type: spec-plan-auto
  description: "Generate Plan"
  prompt: |
    WORKTREE_ROOT: <from stage 1>
    BRANCH_NAME: <from stage 1>
    FEATURE_DIR: <from stage 1>
    Main repo root: <repo root>

    Generate the technical implementation plan and supporting design documents.
```

**Checkpoint**:
- Confirm `plan.md` was generated and Constitution Check passed.
- Run Stage 3 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 3.5: Impact Pre-Analysis (Lightweight)

After plan.md is generated, run a lightweight impact analysis based on the planned changes
to identify cross-module risks before task generation.

```
Task:
  subagent_type: impact-analyzer
  description: "Pre-implementation impact analysis"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Main repo root: <repo root>

    This is a PRE-IMPLEMENTATION analysis based on the technical plan (no code
    changes yet). Read these files:
    - <FEATURE_DIR>/plan.md (planned architecture and module changes)
    - <FEATURE_DIR>/spec.md (functional requirements)
    - <FEATURE_DIR>/data-model.md (if exists, planned schema changes)

    Analyze:
    1. Which existing modules will be touched or depended upon
    2. Cross-module call chains that may be affected
    3. Schema changes that could impact existing queries
    4. SLA risks from planned new queries or service calls

    Output your standard Impact Analysis Report to:
    <FEATURE_DIR>/impact-pre-analysis.md
    Mark confidence as LOW for items based only on plan intent (no actual diff available yet).
```

**Checkpoint**:
- Parse `<FEATURE_DIR>/impact-pre-analysis.md`. If CRITICAL downstream risks found, append them as
warnings to plan.md and ensure tasks generation accounts for them (e.g., add adaptation
tasks for affected downstream modules).
- Run Stage 3.5 gate (Mandatory Stage Gate); only continue on pass.

**Knowledge Feedback**: If the pre-analysis discovered module dependencies or call chain
patterns not yet documented in `chain-topology.md`, the main pipeline MUST append them
(with confidence marked as LOW/PLANNED). This seeds the knowledge base for the full
analysis in Stage 5.5.

---

### Stage 4: Tasks

```
Task:
  subagent_type: spec-tasks-auto
  description: "Generate Tasks"
  prompt: |
    WORKTREE_ROOT: <from stage 1>
    BRANCH_NAME: <from stage 1>
    FEATURE_DIR: <from stage 1>
    Main repo root: <repo root>

    Generate an executable task list organized by user stories.

    Multi-Module Sharding Rule:
    Check if FEATURE_DIR/specs/ contains multiple spec-<module>.md files.
    - Single module (no specs/ subdirectory or only spec.md):
      Generate a single tasks.md as usual.
    - Multiple modules (2+ spec-<module>.md files):
      MUST generate sharded output:
      - tasks-index.md: Global dependency graph, shared setup/foundational
        tasks (Phase 1-2), cross-module integration tasks (Final Phase),
        and a module manifest listing all shards.
      - tasks-<module>.md: Per-module task list (Phase 3+) containing only
        tasks scoped to that module. Each shard must be self-contained —
        a coding worker reading only this shard plus the shared design docs
        (plan.md, data-model.md, contracts/) can execute without needing
        other shards.
      Task IDs use module prefix to avoid collision: e.g., T-auth-001,
      T-asset-001. Shared tasks in tasks-index.md use T-000-xxx.
      Mark cross-module dependencies explicitly:
        `- [ ] T-asset-003 [P] [US2] ... (depends: T-auth-001)`
```

**Checkpoint**:
- Confirm tasks output was generated. For multi-module: verify tasks-index.md
exists and each module in the manifest has a corresponding tasks-<module>.md shard.
- Run Stage 4 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 4-5 Transition: Sync Planning Docs to Main Repo + User Confirmation

#### Sync Planning Documents

After tasks are generated, sync the specs directory from the worktree back to the main repo
for unified management of all feature planning documents:

**Bash:**
```bash
cp -r <WORKTREE_ROOT>/specs/<BRANCH_NAME> <main-repo-root>/specs/
```

**PowerShell:**
```powershell
Copy-Item -Path <WORKTREE_ROOT>/specs/<BRANCH_NAME> -Destination <main-repo-root>/specs/ -Recurse -Force
```

Sync scope is limited to planning artifacts (no source code): spec.md, plan.md, research.md,
data-model.md, contracts/, quickstart.md, tasks.md (or shards), checklists/.

#### User Confirmation

After sync completes, **pause and show summary to user**:

```
============================================================
Specification complete (stages 0-4), artifacts generated in isolated workspace:
  Workspace: <WORKTREE_ROOT>
  Branch: <BRANCH_NAME>
  Specs: <FEATURE_DIR>
  Synced to main repo: <main-repo>/specs/<BRANCH_NAME>/

Generated files:
  - spec.md (with clarifications)
  - plan.md / research.md / data-model.md / contracts/ / quickstart.md
  - tasks.md (N tasks total, M parallelizable)
    or tasks-index.md + tasks-<module>.md shards (multi-module)

Start implementation? (yes/no)
  yes  - Begin stage 5 implementation immediately
  no   - Stop here; you can review artifacts first, then re-run
         /speckit.pipeline to auto-resume from stage 5
============================================================
```

**Wait for user reply**:
- User replies yes/proceed/continue/start -> proceed to stage 5
- User replies no/stop/wait/review -> stop, output final summary (without implementation stage)

---

### Stage 5: Implement (dispatched directly by this command)

This stage is NOT delegated to a single subagent. The main command parses tasks and
dispatches coding workers (low/medium/high) directly based on task file count.

#### 5a. Parse and Split Tasks

Detect task structure:
- **Single-module** (tasks.md only): Parse as before.
- **Multi-module** (tasks-index.md + tasks-<module>.md shards): Read tasks-index.md
  for the module manifest, shared tasks, and cross-module dependency graph. Then read
  each tasks-<module>.md shard.

From the parsed tasks, extract:
- Each task's TaskID, [P] marker, [US#], Phase, file paths
- Group by Phase; within each Phase identify parallel batches vs sequential tasks
- For multi-module: group tasks by module shard, identify inter-module dependencies

Build a scheduler-ready task graph:
- Normalize task file paths (relative to WORKTREE_ROOT) for file-lock checks.
- Materialize dependency edges from explicit `depends:` markers and phase order.
- Compute dispatch priority (`unblocker_score`, then FIFO).

**Split check**: For each task, if it involves 2+ files or multi-step operations, split into
sub-tasks (e.g., T-auth-003 becomes T-auth-003a, T-auth-003b), each handling only 1-2 files.

**Migration pre-scan**: Run version conflict detection (see rules above), record `NEXT_MIGRATION_VERSION`.

#### 5b. Execute: Shared Setup First

Execute shared setup and foundational tasks from tasks-index.md (Phase 1-2) through the
global scheduler. [P] tasks can run concurrently only if:
- active workers < `MAX_PARALLEL_WORKERS`
- no file-lock conflict
- dependencies are satisfied

These MUST complete before any module-specific tasks.

After shared setup completes, run Phase Gate (build check).

#### 5c. Execute: Module-Level Parallel Dispatch

**Single-module**: Execute Phase by Phase as before (skip to 5d rules).

**Multi-module**: After shared setup passes, dispatch module shards in parallel:

```
For each module shard (respecting cross-module dependency order):

  For each Phase within the shard:
    Parallel tasks (marked [P], not touching same file) -> dispatch via scheduler
    Sequential tasks -> dispatch one at a time

    Task dispatch (same as before):
      subagent_type: coding-worker  # tier: low (1 file) | medium (2-5) | high (6+)
      description: "<TaskID> <brief>"
      prompt: |
        Working directory: <WORKTREE_ROOT>
        Task: <TaskID> <full description and file paths> (limit 1-2 files)
        Migration version: <NEXT_MIGRATION_VERSION> (only for migration tasks)
        Reference: <only the doc fragments needed for this task, not full docs>
        Return: changed files, verification results, remaining risks.
```

**Module parallelism rules**:
- Modules with no inter-module dependencies can be dispatched in parallel, bounded by `MAX_PARALLEL_WORKERS`
- If module B depends on module A (declared in tasks-index.md), module B waits until
  the depended task in module A completes, then proceeds
- Within each module, Phase-by-Phase ordering is preserved
- After ALL tasks in a module shard complete, mark that module as done

**After each task completes**: Mark `[x]` in the corresponding tasks file
(tasks.md or tasks-<module>.md).

#### 5d. Phase Gate

After all tasks in a Phase complete (single-module) or after all module shards complete
(multi-module), run the build command:

```bash
cd <WORKTREE_ROOT> && ${BUILD_COMMAND}
```

Pass -> next Phase (or proceed to cross-module integration). Fail -> attempt fix
(max 2 times), still failing -> halt and report.

#### 5e. Execute: Cross-Module Integration (multi-module only)

After all module shards complete and build passes, execute integration tasks from
tasks-index.md (Final Phase). These tasks handle cross-module wiring, shared
configuration, and end-to-end validation.

Run Phase Gate again after integration tasks complete.

#### 5f. Error Handling

- Parallel batch partial failure: others continue; retry failed task once after batch ends
- Sequential task failure: halt current Phase, report blocking point
- Module-level failure (multi-module): other independent modules continue; dependent
  modules are paused. After the batch completes, retry failed module tasks once.
- Timeout: record TaskID, split into smaller sub-tasks and re-dispatch (max 2 retries per
  task; see "Global Execution Contract")

#### 5g. Stage Checkpoint Artifact

Before leaving stage 5, write implementation summary to:
- `<FEATURE_DIR>/implementation-summary.md`

Minimum content:
- Completed task IDs (including shard/task file names)
- Build gate results (pass/fail, retries)
- Migration versions used (if any)
- Remaining known risks

Then run Stage 5 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 5.5: Impact Analysis (Full)

After all implementation tasks complete and `${BUILD_COMMAND}` passes, run a full
impact analysis based on the actual code diff.

```
Task:
  subagent_type: impact-analyzer
  description: "Post-implementation impact analysis"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Main repo root: <repo root>

    This is a POST-IMPLEMENTATION analysis based on actual code changes.

    1. Run: git diff ${BASE_BRANCH}..HEAD --stat  (to get changed file list)
    2. Run: git diff ${BASE_BRANCH}..HEAD          (to get full diff)
    3. For each changed file, trace all callers and downstream dependencies
    4. Cross-reference with chain topology and SLA budgets
    5. Check incident history for affected areas

    Output your standard Impact Analysis Report with HIGH confidence
    (based on real diff), and write it to:
    <FEATURE_DIR>/impact-analysis.md
```

**Checkpoint**:
- Parse `<FEATURE_DIR>/impact-analysis.md`.
- Run Stage 5.5 gate (Mandatory Stage Gate); only continue on pass.

- **No HIGH/CRITICAL risks** -> proceed to Stage 6 (Code Review), pass impact report
  as additional context
- **HIGH/CRITICAL risks found** -> show to user:
  ```
  Impact Analysis found cross-module risks:
  - [CRITICAL] <risk description>
  - [HIGH] <risk description>

  Options:
    proceed  - Continue to code review (risks noted but accepted)
    fix      - Dispatch fix tasks to address risks before review
    stop     - Halt pipeline for manual assessment
  ```
- User selects proceed -> pass risks as context to Stage 6 review
- User selects fix -> dispatch fix tasks via coding-worker, re-run 5.5
- User selects stop -> halt, output summary

#### 5.5a. Knowledge Feedback (after impact report)

Regardless of the user's choice above, the **main pipeline** (not the impact-analyzer)
MUST update the project knowledge base with discoveries from the impact report:

1. **Update `chain-topology.md`**: If the impact report discovered new call chains,
   module dependencies, or SLA observations not already documented:
   - Append new chains to `## Call Chain Patterns`
   - Add/update module dependencies in the `Internal Modules` table
   - Record observed SLA data points in `## SLA Budgets`

2. **Update `incident-log.md`**: If the impact report flagged CRITICAL risks that were
   confirmed (either fixed or accepted with justification):
   - Append a new entry under `## Incidents` with:
     - Date, feature branch name, severity
     - Affected module and risk description
     - Resolution: "fixed in Stage 5.5" / "accepted with justification: ..."
     - Lesson learned for future changes

3. **Skip updates** if the impact report found no new information beyond what is already
   documented in the knowledge base.

This feedback loop ensures the knowledge base grows with each pipeline run, making future
impact analyses progressively more accurate.

---

### Stage 6: Code Review

After all implementation tasks complete and final `${BUILD_COMMAND}` passes,
invoke `project-code-reviewer`:

```
Task:
  subagent_type: project-code-reviewer
  description: "Review implementation"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Branch: <BRANCH_NAME>
    Specs directory: <FEATURE_DIR>

    Review all changes on this branch relative to ${BASE_BRANCH}:
    1. Run git diff ${BASE_BRANCH}..HEAD for the full diff
    2. Validate implementation against <FEATURE_DIR>/spec.md and plan.md
    3. Run your checklist (security, quality, performance, design patterns)
    4. Output structured report to <FEATURE_DIR>/code-review.md:
       Summary: <one-line conclusion>
       Findings:
       - [CRITICAL/HIGH/MEDIUM/LOW] <file:line> <issue description>
       Follow-up:
       - <suggested fix action>
```

**Checkpoint**:
- Parse `<FEATURE_DIR>/code-review.md`, classify by severity.
- Run Stage 6 gate (Mandatory Stage Gate); only continue on pass.

**Show review report to user**, then decide based on results:

- **No CRITICAL/HIGH issues** -> inform user review passed, pipeline complete
- **CRITICAL/HIGH issues exist** -> show issue list, ask user:
  ```
  Code Review found the following issues:
  - [CRITICAL] <issue1>
  - [HIGH] <issue2>
  ...

  Auto-fix? (yes/no)
    yes  - Dispatch each issue to coding-worker for fixing,
           then re-run review
    no   - Stop; you can fix manually then re-run /speckit.pipeline
  ```
- User selects yes -> dispatch each CRITICAL/HIGH finding as a fix task to
  `coding-worker`, then re-run stage 6 (max 2 retry rounds)
- User selects no -> stop, output final summary with unresolved issues list

---

### Stage 7: Test (dispatch spec-test-writer)

After review passes, write and run tests for implemented code.

#### 7a. Determine Test Scope

Extract all completed implementation tasks from tasks.md, identify classes needing tests:
- Service classes -> unit tests
- Controller/Endpoint classes -> API tests
- Utility/Wrapper classes -> unit tests
- Group by module, each test class as an independent small task

#### 7b. Dispatch Test Writing

For each class needing tests, dispatch a `spec-test-writer`:

```
Task:
  subagent_type: spec-test-writer
  description: "Test <ClassName>"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Test target: <full class path, e.g. com.example.modules.xxx.service.XxxService>
    Module name: <module name, e.g. maintenance>
    Reference:
    - Acceptance criteria: <extract relevant acceptance scenarios from spec.md>
    - API contracts: <extract relevant endpoints from contracts/, if any>
    Write the test class and run verification.
```

Test classes for different modules/classes can be dispatched in parallel.

#### 7c. Aggregate Test Results

After all test classes are written, dispatch `test-runner` to execute the full suite
and get a structured summary:

```
Task:
  subagent_type: test-runner
  description: "Run full test suite"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Test command: ${TEST_COMMAND}
    Stack hint: ${STACK}
```

The test-runner agent takes the exact command (from `.specify/.project`), runs it,
parses the output, and returns only a structured pass/fail summary. It does NOT detect
the project type — that was already done during `/speckit.init`.

- **PASS** -> proceed to stage 8
- **FAIL** -> dispatch `spec-test-writer` to fix each failed test (max 2 rounds),
  then re-run `test-runner` to verify
- **TIMEOUT / ERROR** -> halt, report to user with the error details
- Still failing after 2 rounds -> halt, report failed tests, wait for user decision

Persist aggregated test result to `<FEATURE_DIR>/test-summary.md`, then run
Stage 7 gate (Mandatory Stage Gate); only continue on pass.

---

### Stage 8: Merge to Base Branch

After tests pass, auto-merge to `${BASE_BRANCH}`:

#### 8a. Pre-check

Check for uncommitted changes (cross-platform git commands):

```bash
cd <WORKTREE_ROOT> && git status
cd <WORKTREE_ROOT> && git diff --cached
```

- Confirm no uncommitted changes (commit first if any)
- Check diff for sensitive information

#### 8b. Commit Test Code

If stage 7 produced new files (cross-platform git commands), add test files using
`${TEST_DIR}` from `.specify/.project`. If `${TEST_DIR}` is empty, detect in order:
`tests`, `test`, `src/test`; fallback to `.`.

Resolve `TEST_DIR_TO_ADD` before commit:

**Bash:**
```bash
if [[ -n "${TEST_DIR:-}" ]]; then
  TEST_DIR_TO_ADD="${TEST_DIR}"
elif [[ -d tests ]]; then
  TEST_DIR_TO_ADD="tests"
elif [[ -d test ]]; then
  TEST_DIR_TO_ADD="test"
elif [[ -d src/test ]]; then
  TEST_DIR_TO_ADD="src/test"
else
  TEST_DIR_TO_ADD="."
fi
```

**PowerShell:**
```powershell
if ("${TEST_DIR}") { $TEST_DIR_TO_ADD = "${TEST_DIR}" }
elseif (Test-Path tests) { $TEST_DIR_TO_ADD = 'tests' }
elseif (Test-Path test) { $TEST_DIR_TO_ADD = 'test' }
elseif (Test-Path 'src/test') { $TEST_DIR_TO_ADD = 'src/test' }
else { $TEST_DIR_TO_ADD = '.' }
```

```bash
cd <WORKTREE_ROOT> && git add "${TEST_DIR_TO_ADD}" && git commit -m "test: add consolidated tests for <BRANCH_NAME>"
```

Examples for test directory: `src/test/java` (Java), `tests` (Python/Node), `test` (Go/Rust).

#### 8c. Merge

Merge the feature branch to `${BASE_BRANCH}` (cross-platform git command):

```bash
cd <main-repo-root> && git checkout ${BASE_BRANCH} && git merge <BRANCH_NAME> --no-ff -m "feat: merge <BRANCH_NAME> with tests"
```

#### 8d. Confirm Push with User

```
============================================================
Branch <BRANCH_NAME> merged to ${BASE_BRANCH} (local).
  Tests: all passed (N test classes, M test methods)
  Review: PASS

Push to remote? (yes/no)
  yes  - git push origin ${BASE_BRANCH}
  no   - Keep local merge; you can push manually
============================================================
```

- User selects yes -> `git push origin ${BASE_BRANCH}`
- User selects no -> stop

Write merge outcome to `<FEATURE_DIR>/merge-summary.md` (include local merge SHA,
whether pushed, and target branch), then run Stage 8 gate (Mandatory Stage Gate).

---

### Stage 9: Rebuild + Documentation Verification

After merge completes, rebuild and start the service, verify API documentation is accessible.

**Build and deploy** using `${DEPLOY_COMMAND}` from `.specify/.project`:

```bash
cd <main-repo-root> && ${DEPLOY_COMMAND}
```

If `DEPLOY_COMMAND` is empty, skip this stage and inform the user to deploy manually.

**Wait for service startup** (poll health check, max 120 seconds):

**Bash:**
```bash
for i in $(seq 1 24); do
  curl -sf http://localhost:${APP_PORT}/${DOC_PATH} > /dev/null && break
  sleep 5
done
```

**PowerShell:**
```powershell
for ($i = 1; $i -le 24; $i++) {
  try {
    Invoke-WebRequest -Uri "http://localhost:${APP_PORT}/${DOC_PATH}" -UseBasicParsing -ErrorAction Stop | Out-Null
    break
  } catch {
    Start-Sleep -Seconds 5
  }
}
```

If `APP_PORT` or `DOC_PATH` is empty in `.specify/.project`, skip health check polling
and inform the user to verify manually.

Show to user:
```
============================================================
Service rebuilt and started:
  API documentation: http://localhost:${APP_PORT}/${DOC_PATH}
  New API endpoints can be found in the documentation interface
============================================================
```

**If startup fails**, dispatch `log-analyzer` to diagnose:

```
Task:
  subagent_type: log-analyzer
  description: "Diagnose startup failure"
  prompt: |
    Log source: ${SERVICE_LOG_COMMAND}
    Investigation context: Service failed to start after deployment.
    Stack hint: ${STACK}
    Time range: last 5 minutes
```

If `SERVICE_LOG_COMMAND` is empty, instruct the user to provide log output manually.

Persist deployment verification:
- success: write `<FEATURE_DIR>/deploy-healthcheck.md`
- skipped/fallback: write `<FEATURE_DIR>/deploy-skipped.md` with reason

Then run Stage 9 gate (Mandatory Stage Gate).

---

## Final Summary

After all stages complete, show to user:

1. Execution status per stage (success/retry count)
2. Generated file list, task count, MVP suggestion
3. Implementation stage: completed/failed/skipped task count, modified file list, compile status
4. Review results: pass/fail, issue count (by severity), unresolved issues list (if any)
5. Test results: test class count, test method count, pass/fail
6. Merge status: merged/not merged, pushed or not

```
============================================================
Pipeline complete:
  Workspace: <WORKTREE_ROOT>
  Branch: <BRANCH_NAME>
  Specs: <FEATURE_DIR>
  Review: <PASS/FAIL>
  Tests: <N classes, M methods, all passed>
  Merge: <merged to ${BASE_BRANCH} / pending>

Next steps:
  cd <WORKTREE_ROOT>
  /speckit.analyze    - Analyze spec/plan/tasks consistency
  /speckit.implement  - Re-run or continue unfinished tasks
  # Codex CLI equivalents:
  /prompts:speckit.analyze
  /prompts:speckit.implement
============================================================
```
