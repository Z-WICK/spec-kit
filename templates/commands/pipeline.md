---
description: 自动化规格流水线：读取外部需求文档，在隔离 worktree 中自主执行 specify → clarify → plan → tasks → implement
argument-hint: 路径: /path/to/docs 描述: 功能描述
scripts:
  flyway:
    sh: scripts/bash/scan-flyway-versions.sh
    ps: scripts/powershell/scan-flyway-versions.ps1
  alembic:
    sh: scripts/bash/scan-alembic-revisions.sh
    ps: scripts/powershell/scan-alembic-revisions.ps1
---

## User Input

```text
$ARGUMENTS
```

## Execution

Parse user input and extract:
- **Doc path**: the path after "路径:"
- **Feature description**: the text after "描述:"

If either is missing, ask the user to provide: `路径: /path/to/docs 描述: feature overview`

Get the main repo root (`git rev-parse --show-toplevel`).

### Load Project Config

Read `.specify/.project` to load project-specific settings (generated by `/speckit.init`):

```bash
source .specify/.project
```

This provides: `STACK`, `BUILD_COMMAND`, `TEST_COMMAND`, `TEST_DIR`, `DEPLOY_COMMAND`,
`APP_PORT`, `DOC_PATH`, `MIGRATION_TOOL`, `MIGRATION_PATH`, `SERVICE_LOG_COMMAND`, etc.

If `.specify/.project` does not exist, warn the user:
```
WARNING: .specify/.project not found. Run /speckit.init first to detect project config.
```
Then fall back to asking the user for BUILD_COMMAND and TEST_COMMAND before proceeding.

Dispatch subagents sequentially (stages 0-4); stage 5 is dispatched directly by this
command via the `coding-worker` agent (tier selected by task file count: low ≤1, medium 2-5, high 6+).
**If any stage times out or fails, retry with the same parameters.**

### Task Granularity Rules

To prevent subagent timeouts caused by overly long context:
- **Split large tasks**: If a task involves multiple files or multi-step operations, split
  it so each subagent handles only 1-2 files.
- **Single dispatch limit**: Each coding worker call MUST handle only one clear
  small task (e.g., "create one Entity class" or "write one Service method"). Never bundle
  an entire Phase into a single subagent.
- **Context trimming**: Only pass the reference information required for the current task
  in the prompt. Do not pass all design documents in full.

### Subagent Timeout and Chunked Write (Constitution v2.4.0)

- **5-minute hard timeout**: Every subagent call (Task tool) MUST set timeout=300. If a
  subagent has not returned within 5 minutes, MUST stop the call and follow the procedure
  below.
- **Chunked write instruction**: Every subagent prompt MUST include the following reminder:
  "When writing large files (>200 lines), you MUST write in chunks (each chunk <=200 lines)
  to avoid blocking that causes timeouts. Use Create for the first chunk, then Edit to
  append subsequent chunks."
- **Timeout handling procedure**:
  1. Record the timed-out TaskID and known progress.
  2. Split the task into smaller sub-tasks if the original scope was too broad.
  3. Re-dispatch with reduced scope and the chunked-write reminder.
  4. After 2 consecutive timeouts on the same task, halt and report to the user.

### Migration Version Conflict Detection

Before stage 5 begins and before each migration task dispatch, run version detection to avoid conflicts across worktrees and branches.

**For Flyway (Java/Spring)**:

Use the provided script to scan all worktrees and branches for occupied Flyway version numbers:

**Bash:**
```bash
./scripts/bash/scan-flyway-versions.sh <main-repo> <WORKTREE_ROOT>
```

**PowerShell:**
```powershell
./scripts/powershell/scan-flyway-versions.ps1 -MainRepo <main-repo> -WorktreeRoot <WORKTREE_ROOT>
```

**For Alembic (Python)**:

Use the provided script to scan for Alembic revision IDs:

**Bash:**
```bash
./scripts/bash/scan-alembic-revisions.sh <main-repo> <WORKTREE_ROOT>
```

**PowerShell:**
```powershell
./scripts/powershell/scan-alembic-revisions.ps1 -MainRepo <main-repo> -WorktreeRoot <WORKTREE_ROOT>
```

**For Prisma (Node.js/TypeScript)**:

Scan migration directories (cross-platform):

**Bash:**
```bash
ls <main-repo>/prisma/migrations/*/migration.sql 2>/dev/null || true
ls <WORKTREE_ROOT>/prisma/migrations/*/migration.sql 2>/dev/null || true
```

**PowerShell:**
```powershell
Get-ChildItem <main-repo>/prisma/migrations/*/migration.sql -ErrorAction SilentlyContinue
Get-ChildItem <WORKTREE_ROOT>/prisma/migrations/*/migration.sql -ErrorAction SilentlyContinue
```

**General procedure**:
- Merge all occupied version numbers/IDs, take the max +1 (or generate next unique ID) as the starting version
- Pass `NEXT_MIGRATION_VERSION` into every subagent prompt that involves database migrations
- If a feature needs multiple migration files, increment sequentially (e.g., V15, V16, V17... for Flyway)
- Update `NEXT_MIGRATION_VERSION` after each migration task completes

---

### Checkpoint Recovery: Detect Existing Artifacts on Startup

Before dispatching, detect current state and skip completed stages:

1. Check if a matching worktree already exists (`git worktree list` or user input contains WORKTREE_ROOT)
2. If WORKTREE_ROOT exists, check for artifacts under FEATURE_DIR:

| Detected File | Skip Stage |
|---------------|------------|
| spec.md | Stage 0 + 1 |
| spec.md contains `## Clarifications` | Stage 2 |
| plan.md + research.md | Stage 3 |
| plan.md contains impact warnings or `impact-pre-analysis.md` exists | Stage 3.5 |
| tasks.md (or tasks-index.md) | Stage 4 |
| All tasks in tasks.md marked [x] | Stage 5 |
| `impact-analysis.md` exists in FEATURE_DIR | Stage 5.5 |
| Review passed (no CRITICAL/HIGH) | Stage 6 (jump to stage 7 test) |
| Tests exist under src/test/ and `pnpm build` passes | Stage 7 (jump to stage 8 merge) |

3. Resume from the first incomplete stage
4. Report to user: `Detected artifacts for stages 0-N, resuming from stage N+1.`

If user input contains only "描述:" without "路径:" and matches an existing worktree/feature,
enter checkpoint recovery mode.

---

### Stage 0: Read Requirements Documents

```
Task:
  subagent_type: spec-read-docs
  description: "Read requirements docs"
  prompt: |
    Doc path: <parsed path>
    Read all requirements documents under this path and output a structured
    requirements summary.
    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts.
```

**Checkpoint**: Confirm a structured requirements summary was returned; record as `DOCS_SUMMARY`.

---

### Stage 1: Specify + Worktree

```
Task:
  subagent_type: spec-specify-wt
  description: "Specify + Worktree"
  prompt: |
    Requirements summary:
    <DOCS_SUMMARY>

    Feature description: <parsed description>
    Main repo root: <repo root>

    Create an isolated worktree workspace, populate spec.md and quality checklist.
    MUST return WORKTREE_ROOT, BRANCH_NAME, FEATURE_DIR, and main repo root.

    Multi-Module Decomposition (Constitution v2.3.0):
    Count the number of distinct functional modules in the requirements first.
    - 1 module: spec.md contains all content directly.
    - 2-8 modules: spec.md serves as summary entry point only; create
      spec-<module>.md for each submodule under FEATURE_DIR/specs/.
      Reference: specs/009-asset-lifecycle/.
    - >8 modules: STOP and advise the user to split into multiple branches.

    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts. Use Create for the
    first chunk, then Edit to append.
```

**Checkpoint**: Confirm WORKTREE_ROOT / BRANCH_NAME / FEATURE_DIR were returned; record as context variables.

---

### Stage 2: Clarify

```
Task:
  subagent_type: spec-clarify-auto
  description: "Auto Clarify"
  prompt: |
    WORKTREE_ROOT: <from stage 1>
    BRANCH_NAME: <from stage 1>
    FEATURE_DIR: <from stage 1>
    Main repo root: <repo root>

    Automatically clarify ambiguities in spec.md, select recommended answers
    and write them back.
    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts.
```

**Checkpoint**: Confirm clarify completed and spec.md was updated.

---

### Stage 3: Plan

```
Task:
  subagent_type: spec-plan-auto
  description: "Generate Plan"
  prompt: |
    WORKTREE_ROOT: <from stage 1>
    BRANCH_NAME: <from stage 1>
    FEATURE_DIR: <from stage 1>
    Main repo root: <repo root>

    Generate the technical implementation plan and supporting design documents.
    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts.
```

**Checkpoint**: Confirm plan.md was generated and Constitution Check passed.

---

### Stage 3.5: Impact Pre-Analysis (Lightweight)

After plan.md is generated, run a lightweight impact analysis based on the planned changes
to identify cross-module risks before task generation.

```
Task:
  subagent_type: impact-analyzer
  description: "Pre-implementation impact analysis"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Main repo root: <repo root>

    This is a PRE-IMPLEMENTATION analysis based on the technical plan (no code
    changes yet). Read these files:
    - <FEATURE_DIR>/plan.md (planned architecture and module changes)
    - <FEATURE_DIR>/spec.md (functional requirements)
    - <FEATURE_DIR>/data-model.md (if exists, planned schema changes)

    Analyze:
    1. Which existing modules will be touched or depended upon
    2. Cross-module call chains that may be affected
    3. Schema changes that could impact existing queries
    4. SLA risks from planned new queries or service calls

    Output your standard Impact Analysis Report. Mark confidence as LOW for
    items based only on plan intent (no actual diff available yet).

    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts. Use Create for the
    first chunk, then Edit to append.
```

**Checkpoint**: Parse impact report. If CRITICAL downstream risks found, append them as
warnings to plan.md and ensure tasks generation accounts for them (e.g., add adaptation
tasks for affected downstream modules).

**Knowledge Feedback**: If the pre-analysis discovered module dependencies or call chain
patterns not yet documented in `chain-topology.md`, the main pipeline MUST append them
(with confidence marked as LOW/PLANNED). This seeds the knowledge base for the full
analysis in Stage 5.5.

---

### Stage 4: Tasks

```
Task:
  subagent_type: spec-tasks-auto
  description: "Generate Tasks"
  prompt: |
    WORKTREE_ROOT: <from stage 1>
    BRANCH_NAME: <from stage 1>
    FEATURE_DIR: <from stage 1>
    Main repo root: <repo root>

    Generate an executable task list organized by user stories.

    Multi-Module Sharding Rule:
    Check if FEATURE_DIR/specs/ contains multiple spec-<module>.md files.
    - Single module (no specs/ subdirectory or only spec.md):
      Generate a single tasks.md as usual.
    - Multiple modules (2+ spec-<module>.md files):
      MUST generate sharded output:
      - tasks-index.md: Global dependency graph, shared setup/foundational
        tasks (Phase 1-2), cross-module integration tasks (Final Phase),
        and a module manifest listing all shards.
      - tasks-<module>.md: Per-module task list (Phase 3+) containing only
        tasks scoped to that module. Each shard must be self-contained —
        a coding worker reading only this shard plus the shared design docs
        (plan.md, data-model.md, contracts/) can execute without needing
        other shards.
      Task IDs use module prefix to avoid collision: e.g., T-auth-001,
      T-asset-001. Shared tasks in tasks-index.md use T-000-xxx.
      Mark cross-module dependencies explicitly:
        `- [ ] T-asset-003 [P] [US2] ... (depends: T-auth-001)`

    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts.
```

**Checkpoint**: Confirm tasks output was generated. For multi-module: verify tasks-index.md
exists and each module in the manifest has a corresponding tasks-<module>.md shard.

---

### Stage 4-5 Transition: Sync Planning Docs to Main Repo + User Confirmation

#### Sync Planning Documents

After tasks are generated, sync the specs directory from the worktree back to the main repo
for unified management of all feature planning documents:

**Bash:**
```bash
cp -r <WORKTREE_ROOT>/specs/<BRANCH_NAME> <main-repo-root>/specs/
```

**PowerShell:**
```powershell
Copy-Item -Path <WORKTREE_ROOT>/specs/<BRANCH_NAME> -Destination <main-repo-root>/specs/ -Recurse -Force
```

Sync scope is limited to planning artifacts (no source code): spec.md, plan.md, research.md,
data-model.md, contracts/, quickstart.md, tasks.md (or shards), checklists/.

#### User Confirmation

After sync completes, **pause and show summary to user**:

```
============================================================
Specification complete (stages 0-4), artifacts generated in isolated workspace:
  Workspace: <WORKTREE_ROOT>
  Branch: <BRANCH_NAME>
  Specs: <FEATURE_DIR>
  Synced to main repo: <main-repo>/specs/<BRANCH_NAME>/

Generated files:
  - spec.md (with clarifications)
  - plan.md / research.md / data-model.md / contracts/ / quickstart.md
  - tasks.md (N tasks total, M parallelizable)
    or tasks-index.md + tasks-<module>.md shards (multi-module)

Start implementation? (yes/no)
  yes  - Begin stage 5 implementation immediately
  no   - Stop here; you can review artifacts first, then re-run
         /spec-pipeline to auto-resume from stage 5
============================================================
```

**Wait for user reply**:
- User replies yes/proceed/continue/start -> proceed to stage 5
- User replies no/stop/wait/review -> stop, output final summary (without implementation stage)

---

### Stage 5: Implement (dispatched directly by this command)

This stage is NOT delegated to a single subagent. The main command parses tasks and
dispatches coding workers (low/medium/high) directly based on task file count.

#### 5a. Parse and Split Tasks

Detect task structure:
- **Single-module** (tasks.md only): Parse as before.
- **Multi-module** (tasks-index.md + tasks-<module>.md shards): Read tasks-index.md
  for the module manifest, shared tasks, and cross-module dependency graph. Then read
  each tasks-<module>.md shard.

From the parsed tasks, extract:
- Each task's TaskID, [P] marker, [US#], Phase, file paths
- Group by Phase; within each Phase identify parallel batches vs sequential tasks
- For multi-module: group tasks by module shard, identify inter-module dependencies

**Split check**: For each task, if it involves 2+ files or multi-step operations, split into
sub-tasks (e.g., T-auth-003 becomes T-auth-003a, T-auth-003b), each handling only 1-2 files.

**Migration pre-scan**: Run version conflict detection (see rules above), record `NEXT_MIGRATION_VERSION`.

#### 5b. Execute: Shared Setup First

Execute shared setup and foundational tasks from tasks-index.md (Phase 1-2) sequentially
or with [P] parallelism as marked. These MUST complete before any module-specific tasks.

After shared setup completes, run Phase Gate (build check).

#### 5c. Execute: Module-Level Parallel Dispatch

**Single-module**: Execute Phase by Phase as before (skip to 5d rules).

**Multi-module**: After shared setup passes, dispatch module shards in parallel:

```
For each module shard (respecting cross-module dependency order):

  For each Phase within the shard:
    Parallel tasks (marked [P], not touching same file) -> dispatch simultaneously
    Sequential tasks -> dispatch one at a time

    Task dispatch (same as before):
      subagent_type: coding-worker  # tier: low (1 file) | medium (2-5) | high (6+)
      description: "<TaskID> <brief>"
      prompt: |
        Working directory: <WORKTREE_ROOT>
        Task: <TaskID> <full description and file paths> (limit 1-2 files)
        Migration version: <NEXT_MIGRATION_VERSION> (only for migration tasks)
        Reference: <only the doc fragments needed for this task, not full docs>
        WARNING: When writing large files (>200 lines), you MUST write in chunks
        (each chunk <=200 lines) to avoid blocking timeouts. Use Create for the
        first chunk, then Edit to append.
        Return: changed files, verification results, remaining risks.
```

**Module parallelism rules**:
- Modules with no inter-module dependencies can be dispatched fully in parallel
- If module B depends on module A (declared in tasks-index.md), module B waits until
  the depended task in module A completes, then proceeds
- Within each module, Phase-by-Phase ordering is preserved
- After ALL tasks in a module shard complete, mark that module as done

**After each task completes**: Mark `[x]` in the corresponding tasks file
(tasks.md or tasks-<module>.md).

#### 5d. Phase Gate

After all tasks in a Phase complete (single-module) or after all module shards complete
(multi-module), run the build command:

```bash
cd <WORKTREE_ROOT> && ${BUILD_COMMAND}
```

Pass -> next Phase (or proceed to cross-module integration). Fail -> attempt fix
(max 2 times), still failing -> halt and report.

#### 5e. Execute: Cross-Module Integration (multi-module only)

After all module shards complete and build passes, execute integration tasks from
tasks-index.md (Final Phase). These tasks handle cross-module wiring, shared
configuration, and end-to-end validation.

Run Phase Gate again after integration tasks complete.

#### 5f. Error Handling

- Parallel batch partial failure: others continue; retry failed task once after batch ends
- Sequential task failure: halt current Phase, report blocking point
- Module-level failure (multi-module): other independent modules continue; dependent
  modules are paused. After the batch completes, retry failed module tasks once.
- Timeout: record TaskID, split into smaller sub-tasks and re-dispatch (max 2 retries per
  task; see "Subagent Timeout and Chunked Write" rules)

---

### Stage 5.5: Impact Analysis (Full)

After all implementation tasks complete and `pnpm build` passes, run a full
impact analysis based on the actual code diff.

```
Task:
  subagent_type: impact-analyzer
  description: "Post-implementation impact analysis"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Main repo root: <repo root>

    This is a POST-IMPLEMENTATION analysis based on actual code changes.

    1. Run: git diff main..HEAD --stat  (to get changed file list)
    2. Run: git diff main..HEAD          (to get full diff)
    3. For each changed file, trace all callers and downstream dependencies
    4. Cross-reference with chain topology and SLA budgets
    5. Check incident history for affected areas

    Output your standard Impact Analysis Report with HIGH confidence
    (based on real diff).

    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts. Use Create for the
    first chunk, then Edit to append.
```

**Checkpoint**: Parse impact report.

- **No HIGH/CRITICAL risks** -> proceed to Stage 6 (Code Review), pass impact report
  as additional context
- **HIGH/CRITICAL risks found** -> show to user:
  ```
  Impact Analysis found cross-module risks:
  - [CRITICAL] <risk description>
  - [HIGH] <risk description>

  Options:
    proceed  - Continue to code review (risks noted but accepted)
    fix      - Dispatch fix tasks to address risks before review
    stop     - Halt pipeline for manual assessment
  ```
- User selects proceed -> pass risks as context to Stage 6 review
- User selects fix -> dispatch fix tasks via coding-worker, re-run 5.5
- User selects stop -> halt, output summary

#### 5.5a. Knowledge Feedback (after impact report)

Regardless of the user's choice above, the **main pipeline** (not the impact-analyzer)
MUST update the project knowledge base with discoveries from the impact report:

1. **Update `chain-topology.md`**: If the impact report discovered new call chains,
   module dependencies, or SLA observations not already documented:
   - Append new chains to `## Call Chain Patterns`
   - Add/update module dependencies in the `Internal Modules` table
   - Record observed SLA data points in `## SLA Budgets`

2. **Update `incident-log.md`**: If the impact report flagged CRITICAL risks that were
   confirmed (either fixed or accepted with justification):
   - Append a new entry under `## Incidents` with:
     - Date, feature branch name, severity
     - Affected module and risk description
     - Resolution: "fixed in Stage 5.5" / "accepted with justification: ..."
     - Lesson learned for future changes

3. **Skip updates** if the impact report found no new information beyond what is already
   documented in the knowledge base.

This feedback loop ensures the knowledge base grows with each pipeline run, making future
impact analyses progressively more accurate.

---

### Stage 6: Code Review

After all implementation tasks complete and final `pnpm build` passes,
invoke `project-code-reviewer`:

```
Task:
  subagent_type: project-code-reviewer
  description: "Review implementation"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Branch: <BRANCH_NAME>
    Specs directory: <FEATURE_DIR>

    Review all changes on this branch relative to main:
    1. Run git diff main..HEAD for the full diff
    2. Validate implementation against <FEATURE_DIR>/spec.md and plan.md
    3. Run your checklist (security, quality, performance, design patterns)
    4. Output structured report:
       Summary: <one-line conclusion>
       Findings:
       - [CRITICAL/HIGH/MEDIUM/LOW] <file:line> <issue description>
       Follow-up:
       - <suggested fix action>
    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts.
```

**Checkpoint**: Parse review results, classify by severity.

**Show review report to user**, then decide based on results:

- **No CRITICAL/HIGH issues** -> inform user review passed, pipeline complete
- **CRITICAL/HIGH issues exist** -> show issue list, ask user:
  ```
  Code Review found the following issues:
  - [CRITICAL] <issue1>
  - [HIGH] <issue2>
  ...

  Auto-fix? (yes/no)
    yes  - Dispatch each issue to coding-worker for fixing,
           then re-run review
    no   - Stop; you can fix manually then re-run /spec-pipeline
  ```
- User selects yes -> dispatch each CRITICAL/HIGH finding as a fix task to
  `coding-worker`, then re-run stage 6 (max 2 retry rounds)
- User selects no -> stop, output final summary with unresolved issues list

---

### Stage 7: Test (dispatch spec-test-writer)

After review passes, write and run tests for implemented code.

#### 7a. Determine Test Scope

Extract all completed implementation tasks from tasks.md, identify classes needing tests:
- Service classes -> unit tests
- Controller/Endpoint classes -> API tests
- Utility/Wrapper classes -> unit tests
- Group by module, each test class as an independent small task

#### 7b. Dispatch Test Writing

For each class needing tests, dispatch a `spec-test-writer`:

```
Task:
  subagent_type: spec-test-writer
  description: "Test <ClassName>"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Test target: <full class path, e.g. com.example.modules.xxx.service.XxxService>
    Module name: <module name, e.g. maintenance>
    Reference:
    - Acceptance criteria: <extract relevant acceptance scenarios from spec.md>
    - API contracts: <extract relevant endpoints from contracts/, if any>
    Write the test class and run verification.
    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts.
```

Test classes for different modules/classes can be dispatched in parallel.

#### 7c. Aggregate Test Results

After all test classes are written, dispatch `test-runner` to execute the full suite
and get a structured summary:

```
Task:
  subagent_type: test-runner
  description: "Run full test suite"
  prompt: |
    Working directory: <WORKTREE_ROOT>
    Test command: ${TEST_COMMAND}
    Stack hint: ${STACK}

    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts. Use Create for the
    first chunk, then Edit to append.
```

The test-runner agent takes the exact command (from `.specify/.project`), runs it,
parses the output, and returns only a structured pass/fail summary. It does NOT detect
the project type — that was already done during `/speckit.init`.

- **PASS** -> proceed to stage 8
- **FAIL** -> dispatch `spec-test-writer` to fix each failed test (max 2 rounds),
  then re-run `test-runner` to verify
- **TIMEOUT / ERROR** -> halt, report to user with the error details
- Still failing after 2 rounds -> halt, report failed tests, wait for user decision

---

### Stage 8: Merge to main

After tests pass, auto-merge to main:

#### 8a. Pre-check

Check for uncommitted changes (cross-platform git commands):

```bash
cd <WORKTREE_ROOT> && git status
cd <WORKTREE_ROOT> && git diff --cached
```

- Confirm no uncommitted changes (commit first if any)
- Check diff for sensitive information

#### 8b. Commit Test Code

If stage 7 produced new files (cross-platform git commands):

```bash
cd <WORKTREE_ROOT> && git add src/test/ && git commit -m "test: add consolidated tests for <BRANCH_NAME>"
```

Examples for test directory: `src/test/java` (Java), `tests` (Python/Node), `test` (Go/Rust)

#### 8c. Merge

Merge the feature branch to main (cross-platform git command):

```bash
cd <main-repo-root> && git merge <BRANCH_NAME> --no-ff -m "feat: merge <BRANCH_NAME> with tests"
```

#### 8d. Confirm Push with User

```
============================================================
Branch <BRANCH_NAME> merged to main (local).
  Tests: all passed (N test classes, M test methods)
  Review: PASS

Push to remote? (yes/no)
  yes  - git push origin main
  no   - Keep local merge; you can push manually
============================================================
```

- User selects yes -> `git push origin main`
- User selects no -> stop

---

### Stage 9: Rebuild + Documentation Verification

After merge completes, rebuild and start the service, verify API documentation is accessible.

**Build and deploy** using `${DEPLOY_COMMAND}` from `.specify/.project`:

```bash
cd <main-repo-root> && ${DEPLOY_COMMAND}
```

If `DEPLOY_COMMAND` is empty, skip this stage and inform the user to deploy manually.

**Wait for service startup** (poll health check, max 120 seconds):

**Bash:**
```bash
for i in $(seq 1 24); do
  curl -sf http://localhost:${APP_PORT}/${DOC_PATH} > /dev/null && break
  sleep 5
done
```

**PowerShell:**
```powershell
for ($i = 1; $i -le 24; $i++) {
  try {
    Invoke-WebRequest -Uri "http://localhost:${APP_PORT}/${DOC_PATH}" -UseBasicParsing -ErrorAction Stop | Out-Null
    break
  } catch {
    Start-Sleep -Seconds 5
  }
}
```

If `APP_PORT` or `DOC_PATH` is empty in `.specify/.project`, skip health check polling
and inform the user to verify manually.

Show to user:
```
============================================================
Service rebuilt and started:
  API documentation: http://localhost:${APP_PORT}/${DOC_PATH}
  New API endpoints can be found in the documentation interface
============================================================
```

**If startup fails**, dispatch `log-analyzer` to diagnose:

```
Task:
  subagent_type: log-analyzer
  description: "Diagnose startup failure"
  prompt: |
    Log source: ${SERVICE_LOG_COMMAND}
    Investigation context: Service failed to start after deployment.
    Stack hint: ${STACK}
    Time range: last 5 minutes

    WARNING: When writing large files (>200 lines), you MUST write in chunks
    (each chunk <=200 lines) to avoid blocking timeouts. Use Create for the
    first chunk, then Edit to append.
```

If `SERVICE_LOG_COMMAND` is empty, instruct the user to provide log output manually.

---

## Final Summary

After all stages complete, show to user:

1. Execution status per stage (success/retry count)
2. Generated file list, task count, MVP suggestion
3. Implementation stage: completed/failed/skipped task count, modified file list, compile status
4. Review results: pass/fail, issue count (by severity), unresolved issues list (if any)
5. Test results: test class count, test method count, pass/fail
6. Merge status: merged/not merged, pushed or not

```
============================================================
Pipeline complete:
  Workspace: <WORKTREE_ROOT>
  Branch: <BRANCH_NAME>
  Specs: <FEATURE_DIR>
  Review: <PASS/FAIL>
  Tests: <N classes, M methods, all passed>
  Merge: <merged to main / pending>

Next steps:
  cd <WORKTREE_ROOT>
  /analyze    - Analyze spec/plan/tasks consistency
  /implement  - Re-run or continue unfinished tasks
============================================================
```
